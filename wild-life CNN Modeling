# -*- coding: utf-8 -*-
"""notebook85eb983ec7

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/notebook85eb983ec7-186b5e31-4286-44c3-b37a-55b8eb9b2354.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240331/auto/storage/goog4_request%26X-Goog-Date%3D20240331T163800Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D29684de64852bdc313bb215121202f794f4f01a765c846a761931f28e18e43634387f30686ce4bf6701c875b04b61d629a74fcab48e34e8aa4e69559516becb811a100a57f0f320b97dd443df2f86d9b7a45be9d4fdeb06b5f6a60527580d87d0b3b12c4a4b8f68bfcedd47377e9b9a1d52bbc18b31f6d16f6a02eda1916363f61b60cedec69a88173c8690a60b6f26a8d12af3b15f27c9521967995bd7794daaa76ac8e1bf85f94298620c5fe028fefeb6f14039fc03def443af683288394c2a22aa8891c060b8f86b533ef77b8407a38b5c8c8e95fb8f3a91abad6cd4a315b01316b982df4b7bdfcb106690f5e4d6fc9a70309ca90fb097f8bc9ed24364e99
"""

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'wildfire-prediction-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2860500%2F4932759%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240331%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240331T163800Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D567ac9adb1e4c246390ffc1a79ef5ebdb98377d37913af3cfbc3a91c7c3aa807bec214e7e661337651edf85f96c531e210faaa23bc95d5a22b73743b78115a65c0da4e50aec7ab593a3a3329970281a607cf750408f681f62f568665eb18802f48e95710c1135885aee04544c9c78fbc496012ae347a78f514438c5b23b45c45a7ed9ece927f80039642a6db08c443fb16d65faa514607d9fc7cdb68d3c955dfbf97ed7bc8cf3ecf96f98e70a8c4805cf5eb458d7d5319a05efe2bda68e08882a09a715a7d7c3556c927138a5afa8ad6522bf152146d2021c727ad7d06117ccb831baec9443aa581ce82169ee6ac99504a6df0ec78a1b2c8d34789e4b46e9a50'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

"""The dataset " Wildfire Detection" is available a Kaggle (link). The dataset consists of satellite images, each
with dimensions of 350x350 pixels, categorized into two classes: Wildfire and No wildfire, containing
22,710 and 20,140 images, respectively. To facilitate model training, the dataset has been partitioned into
train, test, and validation sets, with approximately 70%, 15%, and 15% of the data allocated to each
subset, respectively. Notably, the dataset includes longitude and latitude coordinates corresponding to
wildfire spots where the area burned exceeds 0.01 acres. Leveraging this geographical information,
satellite images of these areas were extracted using the MapBox API. This approach aims to streamline
the dataset for deep learning applications, facilitating the development of a predictive model capable of
assessing the risk of wildfire occurrence in specific regions

# **Importing Important Libraries**
"""

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix

import os
import cv2
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torch.optim import lr_scheduler
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torchvision.utils as vutils
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, SubsetRandomSampler, Dataset
import matplotlib.pyplot as plt
import numpy as np
import random
import shutil

"""# **Data Pre-Processing**"""

def select_images(source_dir, target_dir, num_images):
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

    classes = os.listdir(source_dir)

    for class_name in classes:
        class_dir = os.path.join(source_dir, class_name)
        target_class_dir = os.path.join(target_dir, class_name)

        if not os.path.exists(target_class_dir):
            os.makedirs(target_class_dir)

        images = os.listdir(class_dir)
        selected_images = random.sample(images, min(num_images, len(images)))
        for image_name in selected_images:
            source_path = os.path.join(class_dir, image_name)
            target_path = os.path.join(target_class_dir, image_name)
            shutil.copyfile(source_path, target_path)

# Specify source and target directories for image selection
source_train_dir = '/kaggle/input/wildfire-prediction-dataset/train'
source_valid_dir = '/kaggle/input/wildfire-prediction-dataset/valid'
source_test_dir = '/kaggle/input/wildfire-prediction-dataset/test'

target_train_dir = '/kaggle/working/selected_train'
target_valid_dir = '/kaggle/working/selected_valid'
target_test_dir = '/kaggle/working/selected_test'


select_images(source_train_dir, target_train_dir, num_images=1000)  # Select images for training set
select_images(source_train_dir, target_train_dir, num_images=1000)  # Select images for training set
select_images(source_valid_dir, target_valid_dir, num_images=300)  # Select images for validation set

select_images(source_test_dir, target_test_dir, num_images=300)   # Select images for test set

transform = transforms.Compose([   # Normalize Pixel Values and Step 3: Resize Images
    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Randomly adjust brightness, contrast, and saturation
    transforms.Resize((128, 128)),  # Resize the image to 128*128
    transforms.ToTensor(),  # Convert the image to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image according to the ImageNet statistics
])

# Step 4: Scale Values
train_dataset = datasets.ImageFolder(root=target_train_dir, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

valid_dataset = datasets.ImageFolder(root=target_valid_dir, transform=transform)
valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)

test_dataset = datasets.ImageFolder(root=target_test_dir, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

"""**Image Pixels After Pre-Processing**"""

train_dataset[0]

"""**Converting to training, testing and validation set**"""

def count_images_per_class(directory):
    classes = os.listdir(directory)
    class_counts = {}
    for class_name in classes:
        class_dir = os.path.join(directory, class_name)
        num_images = len(os.listdir(class_dir))
        class_counts[class_name] = num_images
    return class_counts

# Define directories for training, validation, and test sets
train_dir = '/kaggle/working/selected_train'
valid_dir = '/kaggle/working/selected_valid'
test_dir = '/kaggle/working/selected_test'

train_counts = count_images_per_class(train_dir) # Count the number of images in each class for each set
valid_counts = count_images_per_class(valid_dir)
test_counts = count_images_per_class(test_dir)

# Display the counts
print("Training set:")
print(train_counts)
print("Validation set:")
print(valid_counts)
print("Test set:")
print(test_counts)

"""# **CNN Model**"""

class CNNModel(nn.Module):     # 4 CNN
    def __init__(self, num_classes):
        super(CNNModel, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)

        self.relu = nn.ReLU(inplace=True)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        self.fc1 = nn.Linear(256 * 8 * 8, 512)  # Adjust input size based on your image dimensions
        self.fc2 = nn.Linear(512, 256)
        self.fc_out = nn.Linear(256, num_classes)
        self.batch_norm1 = nn.BatchNorm2d(32)
        self.batch_norm2 = nn.BatchNorm2d(64)
        self.batch_norm3 = nn.BatchNorm2d(128)
        self.batch_norm4 = nn.BatchNorm2d(256)

        self.dropout = nn.Dropout(p=0.5)  # Optional dropout layer

    def forward(self, x):    # followed by Relu Activation Function
        x = self.conv1(x)
        x = self.batch_norm1(x)    #  batch normal layers
        x = self.relu(x)
        x = self.pool(x)
        x = self.conv2(x)
        x = self.batch_norm2(x)
        x = self.relu(x)        # 2 fully connected layers
        x = self.pool(x)

        x = self.conv3(x)
        x = self.batch_norm3(x)
        x = self.relu(x)
        x = self.pool(x)

        x = self.conv4(x)
        x = self.batch_norm4(x)
        x = self.relu(x)
        x = self.pool(x)

        x = x.view(x.size(0), -1)
        x = self.fc1(x)     # 2 fc layers
        x = self.relu(x)
        x = self.dropout(x)  # Optional dropout

        x = self.fc2(x)
        x = self.relu(x)
        x = self.dropout(x)  # Optional dropout

        x = self.fc_out(x)
        return torch.sigmoid(x)     # sigmoid

import torch
import torch.optim as optim
import torch.nn as nn

# Check if CUDA (GPU support) is available, and set device accordingly
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Define your CNNModel class and other necessary components here

# Create an instance of the CNN model for binary classification
model = CNNModel(num_classes=1).to(device)
# Print the model architecture
print(model)

"""**Summary**"""

from torchsummary import summary
input_size = (3, 128, 128)

summary(model, input_size)

def train_model(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels.float().view(-1, 1))
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)
        preds = (outputs > 0.5).float()
        correct += (preds == labels.float().view(-1, 1)).sum().item()
        total += labels.size(0)

    epoch_loss = running_loss / len(train_loader.dataset)
    epoch_accuracy = correct / total
    return epoch_loss, epoch_accuracy

def evaluate_model(model, valid_loader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in valid_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels.float().view(-1, 1))
            running_loss += loss.item() * inputs.size(0)
            preds = (outputs > 0.5).float()
            correct += (preds == labels.float().view(-1, 1)).sum().item()
            total += labels.size(0)

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    epoch_loss = running_loss / len(valid_loader.dataset)
    epoch_accuracy = correct / total
    return epoch_loss, epoch_accuracy, all_preds, all_labels

def test_model(model, test_loader, device):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            preds = (outputs > 0.5).float()

            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return all_preds, all_labels

def plot_confusion_matrix(conf_matrix, target_names):
    plt.figure(figsize=(7, 5))
    plt.imshow(conf_matrix, interpolation='nearest', cmap='Spectral')
    plt.title('Confusion Matrix of Model', fontweight='bold', fontsize=14.0)
    plt.colorbar()

    tick_marks = np.arange(len(target_names))
    plt.xticks(tick_marks, target_names, rotation=45)
    plt.yticks(tick_marks, target_names)

    plt.ylabel('Actual Labels', fontweight='bold', fontsize=13)
    plt.xlabel('Predictioned Labels', fontweight='bold', fontsize=13)

    for i in range(len(target_names)):
        for j in range(len(target_names)):
            plt.text(j, i, str(conf_matrix[i][j]), horizontalalignment='center', color='white')
            plt.tight_layout()
            plt.show()

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from sklearn.metrics import classification_report, confusion_matrix

# Define your model, optimizer, loss function, and data loaders
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)  # Define optimizer with initial learning rate
scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)

train_losses = []
valid_losses = []
train_accuracies = []
valid_accuracies = []

num_epochs = 10  # Set the number of epochs
for epoch in range(num_epochs):
    # Training phase
    train_loss, train_accuracy = train_model(model, train_loader, criterion, optimizer, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Validation phase
    valid_loss, valid_accuracy, _, _ = evaluate_model(model, valid_loader, criterion, device)
    valid_losses.append(valid_loss)
    valid_accuracies.append(valid_accuracy)

    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '
          f'Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_accuracy:.4f}')

    # Update learning rate based on validation loss
    scheduler.step(valid_loss)

# Evaluate the trained model on the test set
test_preds, test_labels = test_model(model, test_loader, device)

# Calculate test accuracy
correct = sum(1 for pred, label in zip(test_preds, test_labels) if pred == label)
test_accuracy = correct / len(test_preds)
print(f'Test Accuracy: {test_accuracy:.4f}')

# Plot the training and validation curves
plt.plot(train_losses, label='Train Loss')
plt.plot(valid_losses, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Generate confusion matrix and classification report
conf_matrix = confusion_matrix(test_labels, test_preds)
class_report = classification_report(test_labels, test_preds)

print("Confusion Matrix:")
plot_confusion_matrix(conf_matrix, target_names=['No Wildfire', 'Wildfire'])
print("\nClassification Report:")
print(class_report)

"""**Another Experiment**"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from sklearn.metrics import classification_report, confusion_matrix

# Define your model, optimizer, loss function, and data loaders
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Define optimizer with initial learning rate
scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)

train_losses = []
valid_losses = []
train_accuracies = []
valid_accuracies = []

num_epochs = 10  # Set the number of epochs
for epoch in range(num_epochs):
    # Training phase
    train_loss, train_accuracy = train_model(model, train_loader, criterion, optimizer, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    # Validation phase
    valid_loss, valid_accuracy, _, _ = evaluate_model(model, valid_loader, criterion, device)
    valid_losses.append(valid_loss)
    valid_accuracies.append(valid_accuracy)

    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '
          f'Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_accuracy:.4f}')

    # Update learning rate based on validation loss
    scheduler.step(valid_loss)

# Evaluate the trained model on the test set
test_preds, test_labels = test_model(model, test_loader, device)

# Calculate test accuracy
correct = sum(1 for pred, label in zip(test_preds, test_labels) if pred == label)
test_accuracy = correct / len(test_preds)
print(f'Test Accuracy: {test_accuracy:.4f}')

# Plot the training and validation curves
plt.plot(train_losses, label='Train Loss')
plt.plot(valid_losses, label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Generate confusion matrix and classification report
conf_matrix = confusion_matrix(test_labels, test_preds)
class_report = classification_report(test_labels, test_preds)

print("Confusion Matrix:")
plot_confusion_matrix(conf_matrix, target_names=['No Wildfire', 'Wildfire'])
print("\nClassification Report:")
print(class_report)

"""# **Other Models**"""

# ResNet Model

import torchvision.models as models
resnet_model = models.resnet18(pretrained=True)
num_ftrs = resnet_model.fc.in_features
resnet_model.fc = nn.Linear(num_ftrs, 2)

# VGG Model
class CustomVGG(nn.Module):
    def __init__(self, num_classes=2):
        super(CustomVGG, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(512 * 7 * 7, 4096)
        self.fc2 = nn.Linear(4096, num_classes)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv3(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv4(x))
        x = F.max_pool2d(x, 2)
        x = x.view(-1, 512 * 7 * 7)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# DenseNet Model

import torchvision.models as models
densenet_model = models.densenet121(pretrained=True)
num_ftrs = densenet_model.classifier.in_features
densenet_model.classifier = nn.Linear(num_ftrs, 2)

# # Efficient Model

# from efficientnet_pytorch import EfficientNet
# efficientnet_model = EfficientNet.from_pretrained('efficientnet-b0')
# num_ftrs = efficientnet_model._fc.in_features
# efficientnet_model._fc = nn.Linear(num_ftrs, 2)

"""**If we want to use any other model, we can use it and the details are mentioned in report.**"""
